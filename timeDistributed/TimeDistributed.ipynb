{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[[ 0. ]]\n",
      "\n",
      " [[ 0.2]]\n",
      "\n",
      " [[ 0.4]]\n",
      "\n",
      " [[ 0.6]]\n",
      "\n",
      " [[ 0.8]]]\n",
      "[[ 0. ]\n",
      " [ 0.2]\n",
      " [ 0.4]\n",
      " [ 0.6]\n",
      " [ 0.8]]\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "# prepare sequence\n",
    "length = 5\n",
    "seq = np.array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(len(seq), 1, 1)\n",
    "y = seq.reshape(len(seq), 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = length\n",
    "n_epoch = 1000\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X)\n",
    "print(y)\n",
    "for value in result:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 170\n",
      "Trainable params: 170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[[ 0. ]\n",
      "  [ 0.2]\n",
      "  [ 0.4]\n",
      "  [ 0.6]\n",
      "  [ 0.8]]]\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1)))\n",
    "model.add(Dense(length))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X)\n",
    "for value in result[0,:]:\n",
    "\tprint('%.1f' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 5, 20)             1920      \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 5, 3)              63        \n",
      "=================================================================\n",
      "Total params: 1,983\n",
      "Trainable params: 1,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[[ 0.   0.   4. ]\n",
      "  [ 0.2  0.3  5. ]\n",
      "  [ 0.4  0.6  6. ]\n",
      "  [ 0.6  0.9  7. ]\n",
      "  [ 0.8  1.2  8. ]]]\n",
      "[[[ 0.0590938   0.12268256  3.04647899]\n",
      "  [ 0.16758834  0.2523506   5.25285435]\n",
      "  [ 0.35180026  0.50280601  6.43093824]\n",
      "  [ 0.61479151  0.91009933  7.10025263]\n",
      "  [ 0.82130527  1.25496888  7.61574411]]]\n",
      "0.1\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "# prepare sequence\n",
    "length = 5\n",
    "#seq = array([i/float(length) for i in range(length)])\n",
    "seq = array([[0, 0, 4], [0.2, 0.3, 5], [0.4, 0.6, 6], [0.6, 0.9, 7], [0.8, 1.2, 8]])\n",
    "\n",
    "X = seq.reshape(1, length, 3)\n",
    "y = seq.reshape(1, length, 3)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 1000\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(length, 3), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(3)))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X)\n",
    "print(result)\n",
    "for value in result[0,:,0]:\n",
    "\tprint('%.1f' % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02797817,  0.05717673],\n",
       "        [ 0.18083747,  0.27187762],\n",
       "        [ 0.3940286 ,  0.5844878 ],\n",
       "        [ 0.61285895,  0.91837245],\n",
       "        [ 0.79498917,  1.19486117]]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2 = array([[1, 1], [1.2, 1.3], [1.4, 0.6], [1.6, 0.9], [0.8, 1.2]])\n",
    "X2 = seq.reshape(1, length, 2)\n",
    "model.predict(X2, batch_size=n_batch, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
